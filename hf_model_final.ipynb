{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Title  \\\n",
      "1006  NZ will be ready to go from first ball: Daryl ...   \n",
      "1007  India shouldn't send team for CWG: Ex-coach Vi...   \n",
      "1008  Perth Scorchers sign pacer from Indonesia for ...   \n",
      "1009  Netflix shuts down AAA game development studio...   \n",
      "1010  Pep Guardiola comments on Kevin de Bruyne's re...   \n",
      "\n",
      "                                                   Data   class sentiment  \n",
      "1006  New Zealand all-rounder Daryl Mitchell said th...  sports  positive  \n",
      "1007  Ex-India badminton coach Vimal Kumar criticise...  sports  negative  \n",
      "1008  Perth Scorchers have signed Indonesia seamer N...  sports  positive  \n",
      "1009  AAA game development studio, Team Blue by Netf...  sports  positive  \n",
      "1010  Head coach Pep Guardiola spoke at the pre-matc...  sports  positive  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the first dataset to get the column labels\n",
    "first_df = pd.read_excel('Labeled_Data/scraped_articles_business_2_with_sentiment.xlsx')\n",
    "columns = first_df.columns  # Extract column names\n",
    "\n",
    "# Load all sheets and concatenate using the columns from the first dataset\n",
    "sheets = ['Labeled_Data/scraped_articles_business_2_with_sentiment.xlsx', 'Labeled_Data/scraped_articles_business1_with_sentiment.xlsx'\n",
    "          , 'Labeled_Data/scraped_articles_tech_with_sentiment.xlsx', 'Labeled_Data/scraped_articles_with_sentiment.xlsx']\n",
    "dfs = [pd.read_excel(sheet, names=columns) for sheet in sheets]  # Use the same column names\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    629\n",
      "negative    629\n",
      "neutral     629\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "positive = df[df['sentiment'] == 'positive']\n",
    "negative = df[df['sentiment'] == 'negative']\n",
    "neutral = df[df['sentiment'] == 'neutral']\n",
    "\n",
    "negative_upsampled = resample(negative, replace=True, n_samples=len(positive), random_state=42)\n",
    "neutral_upsampled = resample(neutral, replace=True, n_samples=len(positive), random_state=42)\n",
    "\n",
    "df_upsampled = pd.concat([positive, negative_upsampled, neutral_upsampled])\n",
    "\n",
    "print(df_upsampled['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Data</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Companies’ earnings reports increase volatilit...</td>\n",
       "      <td>Share prices swing as high valuations and unce...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Companies’ earnings reports increase volatilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nasdaq hits record high as tech stocks rebound...</td>\n",
       "      <td>Sharp turnaround from 15% slide as investors m...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Nasdaq hits record high as tech stocks rebound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The problem with the Trump trade</td>\n",
       "      <td>Speculative hedge funds are placing bets but o...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>The problem with the Trump trade: Speculative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Karma comes for Boeing’s shareholders</td>\n",
       "      <td>Nearly a fifth of total shares will soon be ow...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Karma comes for Boeing’s shareholders: Nearly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bond market braced for rise in UK debt issuanc...</td>\n",
       "      <td>Investment banks pencil in second-biggest annu...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Bond market braced for rise in UK debt issuanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Crypto exchanges turn to derivatives to lure c...</td>\n",
       "      <td>New market entrants switch focus to offering l...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Crypto exchanges turn to derivatives to lure c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Georgia’s disputed election</td>\n",
       "      <td>Pivotal election widely seen as a choice betwe...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Georgia’s disputed election: Pivotal election ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Meet the salad hawkers that are valued like te...</td>\n",
       "      <td>But rally for Sweetgreen and Cava may not stay...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Meet the salad hawkers that are valued like te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Crocs doubled down on ugly. It is paying off</td>\n",
       "      <td>Maker of foam clogs has gone from laughing sto...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Crocs doubled down on ugly. It is paying off: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Top US regulator warns of potential crisis if ...</td>\n",
       "      <td>Finance industry steps up effort to further un...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Top US regulator warns of potential crisis if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "1   Companies’ earnings reports increase volatilit...   \n",
       "2   Nasdaq hits record high as tech stocks rebound...   \n",
       "8                    The problem with the Trump trade   \n",
       "12              Karma comes for Boeing’s shareholders   \n",
       "13  Bond market braced for rise in UK debt issuanc...   \n",
       "18  Crypto exchanges turn to derivatives to lure c...   \n",
       "20                        Georgia’s disputed election   \n",
       "28  Meet the salad hawkers that are valued like te...   \n",
       "30       Crocs doubled down on ugly. It is paying off   \n",
       "32  Top US regulator warns of potential crisis if ...   \n",
       "\n",
       "                                                 Data           class  \\\n",
       "1   Share prices swing as high valuations and unce...  stock business   \n",
       "2   Sharp turnaround from 15% slide as investors m...  stock business   \n",
       "8   Speculative hedge funds are placing bets but o...  stock business   \n",
       "12  Nearly a fifth of total shares will soon be ow...  stock business   \n",
       "13  Investment banks pencil in second-biggest annu...  stock business   \n",
       "18  New market entrants switch focus to offering l...  stock business   \n",
       "20  Pivotal election widely seen as a choice betwe...  stock business   \n",
       "28  But rally for Sweetgreen and Cava may not stay...  stock business   \n",
       "30  Maker of foam clogs has gone from laughing sto...  stock business   \n",
       "32  Finance industry steps up effort to further un...  stock business   \n",
       "\n",
       "   sentiment                                      combined_text  \n",
       "1   positive  Companies’ earnings reports increase volatilit...  \n",
       "2   positive  Nasdaq hits record high as tech stocks rebound...  \n",
       "8   positive  The problem with the Trump trade: Speculative ...  \n",
       "12  positive  Karma comes for Boeing’s shareholders: Nearly ...  \n",
       "13  positive  Bond market braced for rise in UK debt issuanc...  \n",
       "18  positive  Crypto exchanges turn to derivatives to lure c...  \n",
       "20  positive  Georgia’s disputed election: Pivotal election ...  \n",
       "28  positive  Meet the salad hawkers that are valued like te...  \n",
       "30  positive  Crocs doubled down on ugly. It is paying off: ...  \n",
       "32  positive  Top US regulator warns of potential crisis if ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_upsampled['combined_text'] = df_upsampled['Title'] + ': ' + df_upsampled['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Data</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Eni to sell 25% stake in biofuel unit to KKR</td>\n",
       "      <td>Italian group will use investment to help fund...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Eni to sell 25% stake in biofuel unit to KKR: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>SpaceX wins $733 million launch contract from ...</td>\n",
       "      <td>Elon Musk-led SpaceX has won a $733 million co...</td>\n",
       "      <td>technology</td>\n",
       "      <td>neutral</td>\n",
       "      <td>SpaceX wins $733 million launch contract from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Elon Musk donates $75 million to pro-Trump gro...</td>\n",
       "      <td>Billionaire Elon Musk donated around $75 milli...</td>\n",
       "      <td>technology</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Elon Musk donates $75 million to pro-Trump gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Netflix sees 35% QoQ jump in ads membership; Q...</td>\n",
       "      <td>Netflix has posted 35% quarter-on-quarter jump...</td>\n",
       "      <td>technology</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Netflix sees 35% QoQ jump in ads membership; Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Production at Tata's iPhone plant in Tamil Nad...</td>\n",
       "      <td>Tata Electronics has indefinitely suspended pr...</td>\n",
       "      <td>technology</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Production at Tata's iPhone plant in Tamil Nad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>No more Bazball: Rizwan teases Brook for playi...</td>\n",
       "      <td>Pakistan wicketkeeper Muhammad Rizwan teased E...</td>\n",
       "      <td>sports</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No more Bazball: Rizwan teases Brook for playi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Emerging markets are having a moment</td>\n",
       "      <td>US interest rate cuts spur reassessment of ass...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Emerging markets are having a moment: US inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Politics is distorting economic data</td>\n",
       "      <td>Partisanship continues to pollute results of i...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Politics is distorting economic data: Partisan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Jellysmack laying off employees amid reorganis...</td>\n",
       "      <td>Jellysmack, a SoftBank-backed creator-economy ...</td>\n",
       "      <td>technology</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Jellysmack laying off employees amid reorganis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>Batted at 8 in IPL 2024 to give Jadeja, Dube c...</td>\n",
       "      <td>Discussing his decision of batting at eight in...</td>\n",
       "      <td>sports</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Batted at 8 in IPL 2024 to give Jadeja, Dube c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "57        Eni to sell 25% stake in biofuel unit to KKR   \n",
       "449  SpaceX wins $733 million launch contract from ...   \n",
       "483  Elon Musk donates $75 million to pro-Trump gro...   \n",
       "465  Netflix sees 35% QoQ jump in ads membership; Q...   \n",
       "668  Production at Tata's iPhone plant in Tamil Nad...   \n",
       "889  No more Bazball: Rizwan teases Brook for playi...   \n",
       "112               Emerging markets are having a moment   \n",
       "10                Politics is distorting economic data   \n",
       "423  Jellysmack laying off employees amid reorganis...   \n",
       "685  Batted at 8 in IPL 2024 to give Jadeja, Dube c...   \n",
       "\n",
       "                                                  Data           class  \\\n",
       "57   Italian group will use investment to help fund...  stock business   \n",
       "449  Elon Musk-led SpaceX has won a $733 million co...      technology   \n",
       "483  Billionaire Elon Musk donated around $75 milli...      technology   \n",
       "465  Netflix has posted 35% quarter-on-quarter jump...      technology   \n",
       "668  Tata Electronics has indefinitely suspended pr...      technology   \n",
       "889  Pakistan wicketkeeper Muhammad Rizwan teased E...          sports   \n",
       "112  US interest rate cuts spur reassessment of ass...  stock business   \n",
       "10   Partisanship continues to pollute results of i...  stock business   \n",
       "423  Jellysmack, a SoftBank-backed creator-economy ...      technology   \n",
       "685  Discussing his decision of batting at eight in...          sports   \n",
       "\n",
       "    sentiment                                      combined_text  \n",
       "57    neutral  Eni to sell 25% stake in biofuel unit to KKR: ...  \n",
       "449   neutral  SpaceX wins $733 million launch contract from ...  \n",
       "483   neutral  Elon Musk donates $75 million to pro-Trump gro...  \n",
       "465   neutral  Netflix sees 35% QoQ jump in ads membership; Q...  \n",
       "668   neutral  Production at Tata's iPhone plant in Tamil Nad...  \n",
       "889   neutral  No more Bazball: Rizwan teases Brook for playi...  \n",
       "112   neutral  Emerging markets are having a moment: US inter...  \n",
       "10    neutral  Politics is distorting economic data: Partisan...  \n",
       "423   neutral  Jellysmack laying off employees amid reorganis...  \n",
       "685   neutral  Batted at 8 in IPL 2024 to give Jadeja, Dube c...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (4.46.1)\n",
      "Requirement already satisfied: tensorflow in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (2.18.0)\n",
      "Requirement already satisfied: datasets in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (3.0.2)\n",
      "Requirement already satisfied: filelock in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: rich in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: namex in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (3.16.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data = {\n",
    "    'combined_text': df_upsampled['combined_text'],  # Use your combined text column\n",
    "    'label': df_upsampled['class']  # Replace with your actual labels column\n",
    "}\n",
    "\n",
    "label_mapping = {\n",
    "    'sports': 0,\n",
    "    'technology': 1,\n",
    "    'stock business': 2\n",
    "    # Add more mappings if you have more classes\n",
    "}\n",
    "\n",
    "# Convert the labels\n",
    "data['label'] = data['label'].map(label_mapping)\n",
    "\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (4.46.1)\n",
      "Requirement already satisfied: peft in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
      "Requirement already satisfied: filelock in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: psutil in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from peft) (1.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\"\"\"\n",
    "model_name_2 = \"dstefa/roberta-base_topic_classification_nyt_news\"\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(model_name_2)\n",
    "model_2 = TFAutoModelForSequenceClassification.from_pretrained(model_name_2)\n",
    "\n",
    "model_name_3 = \"dima806/news-category-classifier-distilbert\"\n",
    "tokenizer_3 = AutoTokenizer.from_pretrained(model_name_3)\n",
    "model_3 = TFAutoModelForSequenceClassification.from_pretrained(model_name_3)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1509 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"combined_text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for TensorFlow\n",
    "tokenized_train_dataset.set_format(type='tensorflow', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_test_dataset.set_format(type='tensorflow', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "\n",
    "train_tf_dataset = tokenized_train_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask'],\n",
    "    label_cols=['label'],\n",
    "    shuffle=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "test_tf_dataset = tokenized_test_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask'],\n",
    "    label_cols=['label'],\n",
    "    shuffle=False,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "189/189 [==============================] - 656s 3s/step - loss: 0.3988 - accuracy: 0.8635 - val_loss: 0.1524 - val_accuracy: 0.9497\n",
      "Epoch 2/3\n",
      "189/189 [==============================] - 634s 3s/step - loss: 0.1223 - accuracy: 0.9622 - val_loss: 0.1240 - val_accuracy: 0.9603\n",
      "Epoch 3/3\n",
      "189/189 [==============================] - 901s 5s/step - loss: 0.0736 - accuracy: 0.9795 - val_loss: 0.1320 - val_accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2f6a58110>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_tf_dataset, epochs=3, validation_data=test_tf_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 158s 3s/step - loss: 0.1320 - accuracy: 0.9524\n",
      "Test Accuracy: 0.9523809552192688\n",
      "48/48 [==============================] - 161s 3s/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_tf_dataset)\n\u001b[0;32m----> 7\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions\u001b[38;5;241m.\u001b[39mlogits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\"\"\"loss, accuracy = model.evaluate(test_tf_dataset)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\"\"\"\n",
    "# Get predictions\n",
    "predictions = model.predict(test_tf_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted_labels = np.argmax(predictions.logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        sports       1.00      1.00      1.00       103\n",
      "    technology       0.94      0.94      0.94       150\n",
      "stock business       0.93      0.93      0.93       125\n",
      "\n",
      "      accuracy                           0.95       378\n",
      "     macro avg       0.96      0.96      0.96       378\n",
      "  weighted avg       0.95      0.95      0.95       378\n",
      "\n",
      "[[103   0   0]\n",
      " [  0 141   9]\n",
      " [  0   9 116]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Get true labels from the test dataset\n",
    "true_labels = np.concatenate([y for _, y in test_tf_dataset], axis=0)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=['sports', 'technology', 'stock business']))\n",
    "print(confusion_matrix(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ArticleTag/tokenizer_config.json',\n",
       " 'ArticleTag/special_tokens_map.json',\n",
       " 'ArticleTag/vocab.txt',\n",
       " 'ArticleTag/added_tokens.json',\n",
       " 'ArticleTag/tokenizer.json')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained('ArticleTag')\n",
    "tokenizer.save_pretrained('ArticleTag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reetvikchatterjee/Desktop/ArticleTag\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../ArticleTagModel1 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_79']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ../ArticleTagModel1 and are newly initialized: ['dropout_912']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the model using the Hugging Face library\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"../ArticleTagModel1\", from_pt=False)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../ArticleTagModel1\")\n",
    "\n",
    "# Prediction function\n",
    "def predict_text(input_text):\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"tf\", truncation=True, padding=True)\n",
    "\n",
    "    # Perform prediction\n",
    "    logits = model(inputs[\"input_ids\"]).logits\n",
    "    predicted_label = tf.argmax(logits, axis=1).numpy()[0]\n",
    "    return predicted_label\n",
    "\n",
    "# Example usage\n",
    "new_text = \"I love being a cricket.\"\n",
    "prediction = predict_text(new_text)\n",
    "print(f\"Predicted Label: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tf-keras\n",
      "  Obtaining dependency information for tf-keras from https://files.pythonhosted.org/packages/8a/ed/e08afca471299b04a34cd548e64e89d0153eda0e6cf9b715356777e24774/tf_keras-2.18.0-py3-none-any.whl.metadata\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (58.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Collecting keras>=3.5.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Obtaining dependency information for keras>=3.5.0 from https://files.pythonhosted.org/packages/c2/88/eef50051a772dcb4433d1f3e4c1d6576ba450fe83e89d028d7e8b85a2122/keras-3.6.0-py3-none-any.whl.metadata\n",
      "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.37.0)\n",
      "Requirement already satisfied: rich in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.3)\n",
      "Requirement already satisfied: namex in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (6.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.16.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/reetvikchatterjee/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: keras, tf-keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "Successfully installed keras-3.6.0 tf-keras-2.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tf-keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Data</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Companies’ earnings reports increase volatilit...</td>\n",
       "      <td>Share prices swing as high valuations and unce...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Companies’ earnings reports increase volatilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nasdaq hits record high as tech stocks rebound...</td>\n",
       "      <td>Sharp turnaround from 15% slide as investors m...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Nasdaq hits record high as tech stocks rebound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The problem with the Trump trade</td>\n",
       "      <td>Speculative hedge funds are placing bets but o...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>The problem with the Trump trade: Speculative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Karma comes for Boeing’s shareholders</td>\n",
       "      <td>Nearly a fifth of total shares will soon be ow...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Karma comes for Boeing’s shareholders: Nearly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bond market braced for rise in UK debt issuanc...</td>\n",
       "      <td>Investment banks pencil in second-biggest annu...</td>\n",
       "      <td>stock business</td>\n",
       "      <td>positive</td>\n",
       "      <td>Bond market braced for rise in UK debt issuanc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "1   Companies’ earnings reports increase volatilit...   \n",
       "2   Nasdaq hits record high as tech stocks rebound...   \n",
       "8                    The problem with the Trump trade   \n",
       "12              Karma comes for Boeing’s shareholders   \n",
       "13  Bond market braced for rise in UK debt issuanc...   \n",
       "\n",
       "                                                 Data           class  \\\n",
       "1   Share prices swing as high valuations and unce...  stock business   \n",
       "2   Sharp turnaround from 15% slide as investors m...  stock business   \n",
       "8   Speculative hedge funds are placing bets but o...  stock business   \n",
       "12  Nearly a fifth of total shares will soon be ow...  stock business   \n",
       "13  Investment banks pencil in second-biggest annu...  stock business   \n",
       "\n",
       "   sentiment                                      combined_text  \n",
       "1   positive  Companies’ earnings reports increase volatilit...  \n",
       "2   positive  Nasdaq hits record high as tech stocks rebound...  \n",
       "8   positive  The problem with the Trump trade: Speculative ...  \n",
       "12  positive  Karma comes for Boeing’s shareholders: Nearly ...  \n",
       "13  positive  Bond market braced for rise in UK debt issuanc...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data = {\n",
    "    'combined_text': df_upsampled['combined_text'],  # Use your combined text column\n",
    "    'label': df_upsampled['sentiment']  # Replace with your actual labels column\n",
    "}\n",
    "\n",
    "label_mapping = {\n",
    "    'positive': 0,\n",
    "    'negative': 1,\n",
    "    'neutral': 2\n",
    "    # Add more mappings if you have more classes\n",
    "}\n",
    "\n",
    "# Convert the labels\n",
    "data['label'] = data['label'].map(label_mapping)\n",
    "\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a07815d7ca413790fbe3fc352830f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"shashanksrinath/News_Sentiment_Analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, from_pt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c9052e8845441cbd5c841652a1abb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1509 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3a69237eef491696094fe8ae0b60f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Ensure tokenization includes padding and truncation for consistency\n",
    "    return tokenizer(\n",
    "        examples[\"combined_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128  # You can adjust this based on your dataset\n",
    "    )\n",
    "\n",
    "# Apply tokenization to the datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for TensorFlow compatibility\n",
    "tokenized_train_dataset.set_format(type='tensorflow', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_test_dataset.set_format(type='tensorflow', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Convert datasets to TensorFlow format using a data collator for padding\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Instantiate the data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_tf_dataset = tokenized_train_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask'],  # Features\n",
    "    label_cols='label',                       # Labels\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "test_tf_dataset = tokenized_test_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask'],  # Features\n",
    "    label_cols='label',                       # Labels\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "189/189 [==============================] - 311s 2s/step - loss: 1.0009 - accuracy: 0.5195 - val_loss: 0.7518 - val_accuracy: 0.6614\n",
      "Epoch 2/3\n",
      "189/189 [==============================] - 304s 2s/step - loss: 0.4725 - accuracy: 0.8105 - val_loss: 0.4972 - val_accuracy: 0.8201\n",
      "Epoch 3/3\n",
      "189/189 [==============================] - 303s 2s/step - loss: 0.1859 - accuracy: 0.9370 - val_loss: 0.3833 - val_accuracy: 0.8757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x3493a2b50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_tf_dataset, epochs=3, validation_data=test_tf_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 27s 547ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_tf_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted_labels = np.argmax(predictions.logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.86      0.78      0.82       131\n",
      "    negative       0.87      0.93      0.90       114\n",
      "     neutral       0.89      0.92      0.91       133\n",
      "\n",
      "    accuracy                           0.88       378\n",
      "   macro avg       0.87      0.88      0.88       378\n",
      "weighted avg       0.88      0.88      0.87       378\n",
      "\n",
      "[[102  16  13]\n",
      " [  6 106   2]\n",
      " [ 10   0 123]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Get true labels from the test dataset\n",
    "true_labels = np.concatenate([y for _, y in test_tf_dataset], axis=0)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=['positive', 'negative', 'neutral']))\n",
    "print(confusion_matrix(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TFBaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Perform predictions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Get the model output\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m  \u001b[38;5;66;03m# Extract logits for classification\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Ensure predictions are in the correct format\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# Predictions are probabilities for each class\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TFBaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "for batch in test_tf_dataset:\n",
    "    input_ids = batch[0]['input_ids'].numpy()\n",
    "    true_labels = batch[1].numpy()\n",
    "\n",
    "    # Perform predictions\n",
    "    outputs = model(batch[0])  # Get the model output\n",
    "    predictions = outputs.logits  # Extract logits for classification\n",
    "\n",
    "    # Ensure predictions are in the correct format\n",
    "    if predictions.ndim == 2:  # Predictions are probabilities for each class\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "    else:  # Handle unexpected shapes\n",
    "        raise ValueError(\"Unexpected shape for predictions\")\n",
    "\n",
    "    for i in range(len(input_ids)):\n",
    "        text = tokenizer.decode(input_ids[i], skip_special_tokens=True)  # Decode input IDs to text\n",
    "        true_label = label_map[true_labels[i]]\n",
    "        predicted_label = label_map[predicted_labels[i]]\n",
    "        results.append((text, true_label, predicted_label))\n",
    "\n",
    "# Print the results\n",
    "for i, (text, true_label, predicted_label) in enumerate(results[:10]):  # Limit to first 10 for readability\n",
    "    print(f\"Sample {i + 1}\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted Label: {predicted_label}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ArticleTag/tokenizer_config.json',\n",
       " 'ArticleTag/special_tokens_map.json',\n",
       " 'ArticleTag/vocab.json',\n",
       " 'ArticleTag/merges.txt',\n",
       " 'ArticleTag/added_tokens.json',\n",
       " 'ArticleTag/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('ArticleTag')\n",
    "tokenizer.save_pretrained('ArticleTag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: New/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: New/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('New')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " roberta (TFRobertaMainLaye  multiple                  124645632 \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124645632 (475.49 MB)\n",
      "Trainable params: 124645632 (475.49 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./ArticleTag.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the model using the Hugging Face library\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"./ArticleTag\", from_pt=False)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ArticleTag\")\n",
    "\n",
    "# Prediction function\n",
    "def predict_text(input_text):\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"tf\", truncation=True, padding=True)\n",
    "\n",
    "    # Perform prediction\n",
    "    logits = model(inputs[\"input_ids\"]).logits\n",
    "    predicted_label = tf.argmax(logits, axis=1).numpy()[0]\n",
    "    return predicted_label\n",
    "\n",
    "# Example usage\n",
    "new_text = \"I love being a cricket.\"\n",
    "prediction = predict_text(new_text)\n",
    "print(f\"Predicted Label: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.31165504  0.6304067  -0.27551326 ...  0.35038495  0.533657\n",
      "    0.61381775]\n",
      "  [-0.01692375  0.2869165  -0.44122618 ...  0.44938803  0.27577737\n",
      "    0.22304904]\n",
      "  [-0.18907458  0.41051    -0.26473066 ...  0.8877572   0.06143521\n",
      "    0.28098065]\n",
      "  ...\n",
      "  [ 0.2692316  -0.33955    -0.1720831  ... -0.37169123  0.2138595\n",
      "    0.6617572 ]\n",
      "  [-0.44324592 -0.2816388  -0.42656094 ... -0.8702068  -0.02141165\n",
      "    0.6386123 ]\n",
      "  [-0.3116879   0.6304521  -0.27553228 ...  0.35032886  0.53365624\n",
      "    0.6137781 ]]], shape=(1, 7, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "print(outputs.last_hidden_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
